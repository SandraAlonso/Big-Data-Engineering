{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 2 Big Data",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC2R6-I303eM"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://mirrors.sonic.net/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xzf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init() #instanciar spark session. Es conveniente tener una unica sesion iniciada y actualizada (si existe la utiliza y si no la crea).\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate() #usamos todos los procesadores locales: local[*]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "siejVtvT1CUc",
        "outputId": "abebad54-dbef-4305-c62a-7b5bd8a155e2"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9441c83bab3d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f73ce8ed590>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzeVxDGO2QV3",
        "outputId": "c3cf3f3b-af26-4b2b-b46b-d5d9965d5154"
      },
      "source": [
        "1/2 #comprobar si tengo python 3 (muy recomendable) python3 = 0.5, python2: 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "9b2aYK7V2kHf",
        "outputId": "88b24a3d-22ee-459e-b31b-ba2a35d9be63"
      },
      "source": [
        "df = spark.read.json(\"./sample_data/anscombe.json\") #output = dataframe cuyo tamaño sera el del json\n",
        "df.describe() #devuelve un dataframe\n",
        "df.describe().show() #muestra el contenido\n",
        "df.describe().toPandas() #tiene tamaño maximo, tener cuidado con archivos reales (grandes). Pandas formatea el output\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+------------------+---------------+\n",
            "|summary|Series|                 X|                 Y|_corrupt_record|\n",
            "+-------+------+------------------+------------------+---------------+\n",
            "|  count|    44|                44|                44|              2|\n",
            "|   mean|  null|               9.0| 7.500454545454546|           null|\n",
            "| stddev|  null|3.1988369979626783|1.9592439863084525|           null|\n",
            "|    min|     I|               4.0|               3.1|              [|\n",
            "|    max|    IV|              19.0|             12.74|              ]|\n",
            "+-------+------+------------------+------------------+---------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>summary</th>\n",
              "      <th>Series</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>_corrupt_record</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>count</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mean</td>\n",
              "      <td>None</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.500454545454546</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stddev</td>\n",
              "      <td>None</td>\n",
              "      <td>3.1988369979626783</td>\n",
              "      <td>1.9592439863084525</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>min</td>\n",
              "      <td>I</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.1</td>\n",
              "      <td>[</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>max</td>\n",
              "      <td>IV</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.74</td>\n",
              "      <td>]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  summary Series                   X                   Y _corrupt_record\n",
              "0   count     44                  44                  44               2\n",
              "1    mean   None                 9.0   7.500454545454546            None\n",
              "2  stddev   None  3.1988369979626783  1.9592439863084525            None\n",
              "3     min      I                 4.0                 3.1               [\n",
              "4     max     IV                19.0               12.74               ]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJG4eUrn6g6j",
        "outputId": "4612f6c5-9a35-4f3e-eaf0-d7451523fb57"
      },
      "source": [
        "df.show(3) #muestra los primeros 3 elementos\n",
        "df.printSchema() #muestra el esquema del archivo (informacion principal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----+---------------+\n",
            "|Series|   X|   Y|_corrupt_record|\n",
            "+------+----+----+---------------+\n",
            "|  null|null|null|              [|\n",
            "|     I|10.0|8.04|           null|\n",
            "|     I| 8.0|6.95|           null|\n",
            "+------+----+----+---------------+\n",
            "only showing top 3 rows\n",
            "\n",
            "root\n",
            " |-- Series: string (nullable = true)\n",
            " |-- X: double (nullable = true)\n",
            " |-- Y: double (nullable = true)\n",
            " |-- _corrupt_record: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzKFRBv03EG2"
      },
      "source": [
        "df2= spark.read.parquet(\"fichero.parket\") #lo bueno de los .parquet es que no tiene tamaño maximo (es un directorio) reparte toda la informacion entre ficheros (como Spark en ordenadores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nfvEWqI6p8g"
      },
      "source": [
        "Los dataframes no se modifican, es la principal diferencia con Pandas. Esto es lo que permite distrtibuirlo entre ordenadores. Es dificil sincronizar cambios en distintos ordenadores.\n",
        "Para modificar dataframes crearemos nuevos dataframes basados en otro dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoOaHnza7BQ7",
        "outputId": "d2ab0bdf-137d-4f0d-b3de-abfbe3e4b12d"
      },
      "source": [
        "df.groupBy(\"X\") #no devuelve un dataframe si no objetos agrupados\n",
        "df.groupBy(\"X\").agg({\"Y\":\"min\", \"X\":\"mean\"}).show() #esto ya no es un dataframe sino una tabla con informacion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+------+\n",
            "|   X|avg(X)|min(Y)|\n",
            "+----+------+------+\n",
            "| 8.0|   8.0|  5.25|\n",
            "| 7.0|   7.0|  4.81|\n",
            "|null|  null|  null|\n",
            "| 4.0|   4.0|   3.1|\n",
            "|11.0|  11.0|  7.81|\n",
            "|14.0|  14.0|   8.1|\n",
            "|19.0|  19.0|  12.5|\n",
            "|10.0|  10.0|  7.46|\n",
            "|13.0|  13.0|  7.58|\n",
            "| 6.0|   6.0|  6.08|\n",
            "| 5.0|   5.0|  4.74|\n",
            "| 9.0|   9.0|  7.11|\n",
            "|12.0|  12.0|  8.15|\n",
            "+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shKHmyP08DyD",
        "outputId": "340f9792-3202-4319-ef0c-51450d5be8e3"
      },
      "source": [
        "#Lo mas parecido a SQL siempre sera lo mas eficiente\n",
        "df.select(\"X\") #devuelve un dataframe donde solo esta X\n",
        "df.select(\"X\").count()\n",
        "df.select([\"X\", \"Y\"]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|   X|    Y|\n",
            "+----+-----+\n",
            "|null| null|\n",
            "|10.0| 8.04|\n",
            "| 8.0| 6.95|\n",
            "|13.0| 7.58|\n",
            "| 9.0| 8.81|\n",
            "|11.0| 8.33|\n",
            "|14.0| 9.96|\n",
            "| 6.0| 7.24|\n",
            "| 4.0| 4.26|\n",
            "|12.0|10.84|\n",
            "| 7.0| 4.81|\n",
            "| 5.0| 5.68|\n",
            "|10.0| 9.14|\n",
            "| 8.0| 8.14|\n",
            "|13.0| 8.74|\n",
            "| 9.0| 8.77|\n",
            "|11.0| 9.26|\n",
            "|14.0|  8.1|\n",
            "| 6.0| 6.13|\n",
            "| 4.0|  3.1|\n",
            "+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9HG0VTM9XJX",
        "outputId": "e13e0ae8-bb54-4f5c-e0f5-a0c9f0d9beff"
      },
      "source": [
        "type (df.select([\"X\", \"Y\"]))\n",
        "type (df[\"X\"]) #columna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.column.Column"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxAmea3_9wzr",
        "outputId": "66898422-45a6-4c3a-fba9-d72d8fabf363"
      },
      "source": [
        "df.head(2) #devuelve una lista de filas de tamaño (parametro)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Series=None, X=None, Y=None, _corrupt_record='['),\n",
              " Row(Series='I', X=10.0, Y=8.04, _corrupt_record=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hgSIcbH94qA",
        "outputId": "301e97cc-b1a1-47ef-d46c-ffbca32e6bdb"
      },
      "source": [
        "#Crear una columna de tipo dataframe\n",
        "df.withColumn(\"z\", df[\"X\"]-df[\"Y\"]).show() #recordamos que no se puede modificacr un dataframe, sino que creamos uno nuevo en base a otro"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----+---------------+--------------------+\n",
            "|Series|   X|    Y|_corrupt_record|                   z|\n",
            "+------+----+-----+---------------+--------------------+\n",
            "|  null|null| null|              [|                null|\n",
            "|     I|10.0| 8.04|           null|  1.9600000000000009|\n",
            "|     I| 8.0| 6.95|           null|  1.0499999999999998|\n",
            "|     I|13.0| 7.58|           null|                5.42|\n",
            "|     I| 9.0| 8.81|           null|  0.1899999999999995|\n",
            "|     I|11.0| 8.33|           null|                2.67|\n",
            "|     I|14.0| 9.96|           null|   4.039999999999999|\n",
            "|     I| 6.0| 7.24|           null| -1.2400000000000002|\n",
            "|     I| 4.0| 4.26|           null| -0.2599999999999998|\n",
            "|     I|12.0|10.84|           null|  1.1600000000000001|\n",
            "|     I| 7.0| 4.81|           null|  2.1900000000000004|\n",
            "|     I| 5.0| 5.68|           null| -0.6799999999999997|\n",
            "|    II|10.0| 9.14|           null|  0.8599999999999994|\n",
            "|    II| 8.0| 8.14|           null|-0.14000000000000057|\n",
            "|    II|13.0| 8.74|           null|                4.26|\n",
            "|    II| 9.0| 8.77|           null| 0.23000000000000043|\n",
            "|    II|11.0| 9.26|           null|  1.7400000000000002|\n",
            "|    II|14.0|  8.1|           null|                 5.9|\n",
            "|    II| 6.0| 6.13|           null| -0.1299999999999999|\n",
            "|    II| 4.0|  3.1|           null|  0.8999999999999999|\n",
            "+------+----+-----+---------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L59PowTv-ukH",
        "outputId": "f3004641-4f0e-4810-d905-c3393bc023a5"
      },
      "source": [
        "#Renombrar columnas, sobretodo para agregaciones min(x) o avg(y)\n",
        "df.groupBy(\"X\").agg({\"Y\":\"min\", \"X\":\"mean\"}).withColumnRenamed(\"avg(X)\", \"Final x\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+------+\n",
            "|   X|Final x|min(Y)|\n",
            "+----+-------+------+\n",
            "| 8.0|    8.0|  5.25|\n",
            "| 7.0|    7.0|  4.81|\n",
            "|null|   null|  null|\n",
            "| 4.0|    4.0|   3.1|\n",
            "|11.0|   11.0|  7.81|\n",
            "|14.0|   14.0|   8.1|\n",
            "|19.0|   19.0|  12.5|\n",
            "|10.0|   10.0|  7.46|\n",
            "|13.0|   13.0|  7.58|\n",
            "| 6.0|    6.0|  6.08|\n",
            "| 5.0|    5.0|  4.74|\n",
            "| 9.0|    9.0|  7.11|\n",
            "|12.0|   12.0|  8.15|\n",
            "+----+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR5L9Htn_XUt",
        "outputId": "3e030876-3ec8-48a0-e7bc-6467c8c5a3f4"
      },
      "source": [
        "#Para usar con SQL\n",
        "df.registerTempTable(\"Data\") #Creamos la tabla para utilizarla como SQL\n",
        "spark.sql(\"select Y from Data where X = 10.0\").show() #es mejor hacer las querys con SQL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|   Y|\n",
            "+----+\n",
            "|8.04|\n",
            "|9.14|\n",
            "|7.46|\n",
            "+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wa12JKsAtS7",
        "outputId": "0fa5f2f2-cc38-4c78-8bb4-13011d9879e2"
      },
      "source": [
        "#consulta con llamada\n",
        "df.filter(df[\"X\"]>10).show()\n",
        "#consulta con SQL\n",
        "spark.sql(\"select * from Data where X > 10.0\").show() #es mejor hacer las querys con SQL\n",
        "#Ambos son igual de eficientes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "|   III|13.0|12.74|           null|\n",
            "|   III|11.0| 7.81|           null|\n",
            "|   III|14.0| 8.84|           null|\n",
            "|   III|12.0| 8.15|           null|\n",
            "|    IV|19.0| 12.5|           null|\n",
            "+------+----+-----+---------------+\n",
            "\n",
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II|12.0| 9.13|           null|\n",
            "|   III|13.0|12.74|           null|\n",
            "|   III|11.0| 7.81|           null|\n",
            "|   III|14.0| 8.84|           null|\n",
            "|   III|12.0| 8.15|           null|\n",
            "|    IV|19.0| 12.5|           null|\n",
            "+------+----+-----+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWWtNEh3C4Sj",
        "outputId": "63339079-2a29-44b6-d9e1-ad15d156d458"
      },
      "source": [
        "#Ejercicio Wallmart\n",
        "data = spark.read.csv(\"./walmart_stock.csv\").show() #carga del csv\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|       _c0|               _c1|               _c2|               _c3|               _c4|     _c5|               _c6|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
            "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
            "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
            "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
            "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
            "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
            "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
            "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
            "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
            "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
            "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
            "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
            "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
            "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
            "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
            "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hqv3Dr2DYnR",
        "outputId": "e592f7ac-0879-4cab-e699-262c3497ef3c"
      },
      "source": [
        "data = spark.read.options(header=True).csv(\"./walmart_stock.csv\").show() #carga del csv con cabeceras formateadas"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
            "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
            "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
            "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
            "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
            "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
            "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
            "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
            "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
            "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
            "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
            "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
            "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
            "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
            "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
            "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
            "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
            "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
            "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
            "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
            "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: string (nullable = true)\n",
            " |-- Volume: string (nullable = true)\n",
            " |-- Adj Close: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsqWa3AMEF-0",
        "outputId": "d400954a-d33d-4eca-ad47-fabec823e4a2"
      },
      "source": [
        "data = spark.read.options(header=True).csv(\"./walmart_stock.csv\").printSchema() \n",
        "data = spark.read.options(header=True, inferSchema=True).csv(\"./walmart_stock.csv\").printSchema() #cuando imprimimos el esquema sale que es todo string, con la opcion inferSchema=True salen los tipos de verdad\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: string (nullable = true)\n",
            " |-- High: string (nullable = true)\n",
            " |-- Low: string (nullable = true)\n",
            " |-- Close: string (nullable = true)\n",
            " |-- Volume: string (nullable = true)\n",
            " |-- Adj Close: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Open: double (nullable = true)\n",
            " |-- High: double (nullable = true)\n",
            " |-- Low: double (nullable = true)\n",
            " |-- Close: double (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Adj Close: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyebPHVwEiR_"
      },
      "source": [
        "Hacer ejercicio campus. Ojo con el 7, hay que mirar la documentacion!!"
      ]
    }
  ]
}
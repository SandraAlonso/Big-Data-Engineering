{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sandra Alonso Paz_Predicting dog food spoiling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqXSawcG7XJb"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://mirrors.sonic.net/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xzf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "D3S7xz-67g9j",
        "outputId": "91a31374-e80b-4fea-9a6f-2030363697b9"
      },
      "source": [
        "#Comprobar la sesión de Spark\n",
        "spark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://58d36afda0de:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f1da4452810>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rib2u4B7Zse"
      },
      "source": [
        "#Cargar archivo\n",
        "df = spark.read.format('csv').options(inferSchema=True, header=True).load('dog_food.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx2ETIyK7lY-",
        "outputId": "c1939d76-9183-4d3b-8105-4dcc20d8e329"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- A: integer (nullable = true)\n",
            " |-- B: integer (nullable = true)\n",
            " |-- C: double (nullable = true)\n",
            " |-- D: integer (nullable = true)\n",
            " |-- Spoiled: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF72lPzd7sDc",
        "outputId": "13278afd-be7c-43d2-d6c3-51f0c8fd3a31"
      },
      "source": [
        "#Observamos que no hay nulos y que todos los valores son numéricos\n",
        "df.describe().show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|summary|                 A|                 B|                 C|                 D|            Spoiled|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
            "|  count|               490|               490|               490|               490|                490|\n",
            "|   mean|  5.53469387755102| 5.504081632653061| 9.126530612244897| 5.579591836734694| 0.2857142857142857|\n",
            "| stddev|2.9515204234399057|2.8537966089662063|2.0555451971054275|2.8548369309982857|0.45221563164613465|\n",
            "|    min|                 1|                 1|               5.0|                 1|                0.0|\n",
            "|    max|                10|                10|              14.0|                10|                1.0|\n",
            "+-------+------------------+------------------+------------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTtPlpbR7uge",
        "outputId": "73ceb474-d9ba-44d9-edca-21ea109fabca"
      },
      "source": [
        "#Columnas del dataFrame\n",
        "df.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'B', 'C', 'D', 'Spoiled']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_tq2Ri77x_y",
        "outputId": "931fb87b-03aa-40ef-85ae-0fffa106969b"
      },
      "source": [
        "#Creamos un vectorAssembler para agrupar todas las columnas features\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        'A',\n",
        "        'B',\n",
        "        'C',\n",
        "        'D'],\n",
        "        outputCol='features')\n",
        "output = assembler.transform(df)\n",
        "\n",
        "#Cambiamos el nombre a la columna Spoiled a label para que concuerde con los datos de entrada de los árboles\n",
        "final_data = output.selectExpr(\"Spoiled as label\", \"features as features\")\n",
        "#Mostramos el dataFrame final\n",
        "final_data.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------------+\n",
            "|label|           features|\n",
            "+-----+-------------------+\n",
            "|  1.0| [4.0,2.0,12.0,3.0]|\n",
            "|  1.0| [5.0,6.0,12.0,7.0]|\n",
            "|  1.0| [6.0,2.0,13.0,6.0]|\n",
            "|  1.0| [4.0,2.0,12.0,1.0]|\n",
            "|  1.0| [4.0,2.0,12.0,3.0]|\n",
            "|  1.0|[10.0,3.0,13.0,9.0]|\n",
            "|  1.0| [8.0,5.0,14.0,5.0]|\n",
            "|  1.0| [5.0,8.0,12.0,8.0]|\n",
            "|  1.0| [6.0,5.0,12.0,9.0]|\n",
            "|  1.0| [3.0,3.0,12.0,1.0]|\n",
            "|  1.0| [9.0,8.0,11.0,3.0]|\n",
            "|  1.0|[1.0,10.0,12.0,3.0]|\n",
            "|  1.0|[1.0,5.0,13.0,10.0]|\n",
            "|  1.0|[2.0,10.0,12.0,6.0]|\n",
            "|  1.0|[1.0,10.0,11.0,4.0]|\n",
            "|  1.0| [5.0,3.0,12.0,2.0]|\n",
            "|  1.0| [4.0,9.0,11.0,8.0]|\n",
            "|  1.0| [5.0,1.0,11.0,1.0]|\n",
            "|  1.0|[4.0,9.0,12.0,10.0]|\n",
            "|  1.0| [5.0,8.0,10.0,9.0]|\n",
            "+-----+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45PC13m18N-v"
      },
      "source": [
        "#Importar librerias de clasificación relacionadas con árboles de decisión\n",
        "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier,\n",
        "                                       DecisionTreeClassifier)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EUOO3bg8TCM"
      },
      "source": [
        "#Separamos el conjunto de datos en datos de entrenamiento y de testeo\n",
        "train, test = final_data.randomSplit([0.7, 0.3])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hedKIIDh8iNq"
      },
      "source": [
        "#Instancia de las clases\n",
        "dtc = DecisionTreeClassifier()\n",
        "rfc = RandomForestClassifier(numTrees = 100)\n",
        "gbt = GBTClassifier()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K21yL_c8loM"
      },
      "source": [
        "#Creamos los modelos para cada una de las clases a partir del conjunto de datos de enternamiento\n",
        "dtc_model = dtc.fit(train)\n",
        "rfc_model = rfc.fit(train)\n",
        "gbt_model = gbt.fit(train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PsFZTUwFS5q"
      },
      "source": [
        "#Creamos las predicciones a partir de los modelos creados\n",
        "dtc_preds = dtc_model.transform(test)\n",
        "rfc_preds = rfc_model.transform(test)\n",
        "gbt_preds = gbt_model.transform(test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PniycMVoFUzN",
        "outputId": "23d1fd5e-e9d7-4019-8a1b-2f0e4ab40dc3"
      },
      "source": [
        "#Mostramos las predicciones\n",
        "dtc_preds.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------+-------------+--------------------+----------+\n",
            "|label|          features|rawPrediction|         probability|prediction|\n",
            "+-----+------------------+-------------+--------------------+----------+\n",
            "|  0.0| [1.0,3.0,8.0,3.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [1.0,4.0,8.0,7.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [1.0,4.0,9.0,3.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [1.0,4.0,9.0,6.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [1.0,7.0,7.0,2.0]|   [34.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [1.0,7.0,8.0,4.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0|[1.0,8.0,7.0,10.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [2.0,1.0,8.0,9.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [2.0,1.0,9.0,1.0]|    [6.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0|[2.0,1.0,10.0,7.0]|   [11.0,3.0]|[0.78571428571428...|       0.0|\n",
            "|  0.0| [2.0,2.0,8.0,1.0]|    [6.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [2.0,2.0,9.0,8.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [2.0,4.0,8.0,5.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [2.0,5.0,7.0,6.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [2.0,5.0,8.0,3.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0|[2.0,6.0,8.0,10.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [2.0,8.0,6.0,9.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0|[2.0,9.0,7.0,10.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0|[2.0,10.0,8.0,3.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "|  0.0| [3.0,1.0,8.0,5.0]|  [198.0,0.0]|           [1.0,0.0]|       0.0|\n",
            "+-----+------------------+-------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz0b1VXWFW3O"
      },
      "source": [
        "#Evaluamos la accuracy de las predicciones mediante un multiclass clasification evaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(metricName='accuracy')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DCfKYhCFZfc",
        "outputId": "8147ecb0-f7ff-4182-b45e-f891d0ea2048"
      },
      "source": [
        "#Resultado final\n",
        "print(f'DTC: {evaluator.evaluate(dtc_preds)}') \n",
        "print(f'RFC: {evaluator.evaluate(rfc_preds)}')\n",
        "print(f'GBT: {evaluator.evaluate(gbt_preds)}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DTC: 0.9772727272727273\n",
            "RFC: 0.9924242424242424\n",
            "GBT: 0.9696969696969697\n"
          ]
        }
      ]
    }
  ]
}